{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6e7aec-7d3e-4bc1-85ab-866e0c7cfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "MODEL_PATH=\"/shared/vsathia2/hf_models/relu-llama/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e439fa1-a557-475b-b934-7ed946ab5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e847b5b7e49c1b72f7fdefa2920fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "tokenizer.eos_token = tokenizer.pad_token\n",
    "# max_seq_length = 150\n",
    "m = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map=\"cuda:0\",attn_implementation=\"eager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbd5a31d-a683-4896-becc-0f760eba971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed1bd9d9-9850-4414-9898-49718ac13bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): ReLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7505b1b2-0362-48c4-b71b-0af5d40483a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27db155d-3d11-484a-a401-e176c6894e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"wikitext\",\"wikitext-2-raw-v1\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f48e8e32-137a-44e9-a7c0-cb920b328c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' = Robert Boulter = \\n', '', ' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n', ' In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris Leonti , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris Leonti . \\n']\n",
      "Length of sentence 0 = 0; Sentence - \n",
      "Length of sentence 1 = 21; Sentence -  = Robert Boulter = \n",
      "\n",
      "Length of sentence 2 = 0; Sentence - \n",
      "Length of sentence 3 = 859; Sentence -  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy 's Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \n",
      "\n",
      "Length of sentence 4 = 861; Sentence -  In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris Leonti , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris Leonti . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View some sentences in the test split\n",
    "print(data['test']['text'][:5])\n",
    "for i in range(5):\n",
    "    print(f\"Length of sentence {i} = {len(data['test']['text'][i])}; Sentence - {data['test']['text'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "871ae654-2481-47d5-8560-cff185b4575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4358\n"
     ]
    }
   ],
   "source": [
    "d_train = data[\"train\"]\n",
    "d_test = data[\"test\"]\n",
    "\n",
    "d_test_txt_list = [\" \\n\" if s == \"\" else s for s in d_test[\"text\"]]\n",
    "print(len(d_test_txt_list))\n",
    "d_test_str = \"\".join(d_test_txt_list)\n",
    "d_test_str2 = \"\\n\\n\".join(d_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4de2d3d5-6191-415a-ad1a-a07a711c823f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n = Robert Boulter = \\n \\n Robert Boulter is an English film , television and theatre actor . He had a'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test_str[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94661bb2-98f4-4a47-87e6-02a2e8b000a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n = Robert Boulter = \\n\\n\\n\\n\\n Robert Boulter is an English film , television and theatre actor . He had'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test_str2[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d601fa2-5f78-49c5-bdd0-8fb83d9d4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute encodings on the test dataset\n",
    "embeddings = tokenizer(d_test_str)\n",
    "embeddings2 = tokenizer(d_test_str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c799dd1-2f41-4c36-b663-272d8372dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 259, 13, 353, 4755, 350, 5059, 357, 353, 29871]\n",
      "[1, 29871, 13, 13, 353, 4755, 350, 5059, 357, 353]\n"
     ]
    }
   ],
   "source": [
    "# Check the embedding values for the given tokenizer\n",
    "print(embeddings.input_ids[:10])\n",
    "print(embeddings2.input_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "747b1ebd-d6c8-432e-bd72-d2eb502a60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>  \n",
      " = Robert Boulter = \n",
      " \n",
      " Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy 's Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \n",
      " In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on \n"
     ]
    }
   ],
   "source": [
    "# Decode the given embeddings\n",
    "print(tokenizer.decode(embeddings.input_ids)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea80bc60-1816-43ee-9f6d-8523bdc3e045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "\n",
      " = Robert Boulter = \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy 's Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \n",
      "\n",
      "\n",
      " In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(embeddings2.input_ids)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8923a4d4-c23b-46e9-b0af-e6371d3badf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_test[\"text\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9aefac3-bc9f-45f6-b4f2-4e9cfb13bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_test_str[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33546532-ca21-4a41-8b4a-2100ea98f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer(d_test[\"text\"])\n",
    "tokens2 = tokenizer(d_test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d156123-3e52-4ee2-a64a-3ec6aae6ffc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b13b93d4-8a9e-4e29-8125-1895690fefae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 259, 13, 353, 4755]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2['input_ids'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d407bd9e-f131-481b-bfb7-8d6b3515554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce78c5d935c4f239f396e28276a1553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbf07c502ab487dadfa5c547e711783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5060c7735d714eaaab9faccea95da0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_dataset = data.map(lambda example: tokenizer(example[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d44b8c3-9663-4c93-8921-8ec1518e2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset[\"test\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "053cafd4-b5d9-4b1d-b5fe-33ef9d22258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e585c93-a0a0-4090-98ea-f24f1e0339e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "# from datasets import Dataset\n",
    "# from datasets import load_dataset, load_from_disk\n",
    "\n",
    "\n",
    "def wikitext_detokenize(string):\n",
    "    # contractions\n",
    "    string = string.replace(\"s '\", \"s'\")\n",
    "    string = re.sub(r\"/' [0-9]/\", r\"/'[0-9]/\", string)\n",
    "    # number separators\n",
    "    string = string.replace(\" @-@ \", \"-\")\n",
    "    string = string.replace(\" @,@ \", \",\")\n",
    "    string = string.replace(\" @.@ \", \".\")\n",
    "    # punctuation\n",
    "    string = string.replace(\" : \", \": \")\n",
    "    string = string.replace(\" ; \", \"; \")\n",
    "    string = string.replace(\" . \", \". \")\n",
    "    string = string.replace(\" ! \", \"! \")\n",
    "    string = string.replace(\" ? \", \"? \")\n",
    "    string = string.replace(\" , \", \", \")\n",
    "    # double brackets\n",
    "    string = re.sub(r\"\\(\\s*([^\\)]*?)\\s*\\)\", r\"(\\1)\", string)\n",
    "    string = re.sub(r\"\\[\\s*([^\\]]*?)\\s*\\]\", r\"[\\1]\", string)\n",
    "    string = re.sub(r\"{\\s*([^}]*?)\\s*}\", r\"{\\1}\", string)\n",
    "    string = re.sub(r\"\\\"\\s*([^\\\"]*?)\\s*\\\"\", r'\"\\1\"', string)\n",
    "    string = re.sub(r\"'\\s*([^']*?)\\s*'\", r\"'\\1'\", string)\n",
    "    # miscellaneous\n",
    "    string = string.replace(\"= = = =\", \"====\")\n",
    "    string = string.replace(\"= = =\", \"===\")\n",
    "    string = string.replace(\"= =\", \"==\")\n",
    "    string = string.replace(\" \" + chr(176) + \" \", chr(176))\n",
    "    string = string.replace(\" \\n\", \"\\n\")\n",
    "    string = string.replace(\"\\n \", \"\\n\")\n",
    "    string = string.replace(\" N \", \" 1 \")\n",
    "    string = string.replace(\" 's\", \"'s\")\n",
    "\n",
    "    return string\n",
    "    \n",
    "    \n",
    "def get_wikitext_test_data_loader(args, tokenizer, num_workers=0):\n",
    "    \n",
    "    data = load_from_disk(\"./data/wikitext/test\")\n",
    "    encodings = tokenizer(\"\\n\\n\".join(\n",
    "        [wikitext_detokenize(t) for t in data[\"text\"]]\n",
    "    ), return_tensors=\"pt\")\n",
    "    \n",
    "    input_ids_list = []\n",
    "    stride = args.seq_length\n",
    "    # TODO: last stride is dropped\n",
    "    for i in range(0, encodings.input_ids.size(1)-stride, stride):\n",
    "        begin_loc = i\n",
    "        end_loc = min(i+stride, encodings.input_ids.size(1))\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "        input_ids_list.append(input_ids)\n",
    "    input_ids = torch.cat(input_ids_list, 0)\n",
    "    \n",
    "    train_set = Dataset.from_dict({\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': torch.ones_like(input_ids),\n",
    "        'idx': list(range(len(input_ids))),\n",
    "    })\n",
    "    \n",
    "    train_set = train_set.map(lambda examples: {'text': examples['input_ids']}, batched=True)\n",
    "    train_set.set_format(\n",
    "        type='torch', columns=[\n",
    "            'text', 'input_ids', 'attention_mask', 'idx',\n",
    "        ])\n",
    "    \n",
    "    # TODO: let drop_last be False\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                                    batch_size=args.batch_size,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=num_workers,\n",
    "                                                    drop_last=True,\n",
    "                                                    pin_memory=True,\n",
    "                                                    collate_fn=None)\n",
    "        \n",
    "    return train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9e96aa02-fef5-48da-b6ec-74e48ce0d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "77192aef-dce0-4343-81ac-bece31e91510",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings2 =  tokenizer(\"\\n\\n\".join(\n",
    "        [wikitext_detokenize(t) for t in data[\"train\"][\"text\"]]\n",
    "    ), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fc90a895-1925-4cd6-94da-74c86f0f1097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0602773030598955"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings2.input_ids.shape[1] / 393216.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2507a1db-ecb0-4e39-b8d6-31d9d422341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = tk2.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4ba336aa-3bd5-4641-ac5d-ab15f9f3c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings2 =  tokenizer(\"\\n\\n\".join(\n",
    "        [wikitext_detokenize(t) for t in dtest[\"text\"]]\n",
    "    ), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b634d7d-0668-477a-9d35-53805c596288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 328887])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings2.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8b982-deff-4d67-a98f-3e2ce49306ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3bb769f-02d0-4e11-ba2c-35ed9a9d1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = encodings = tokenizer(\"\\n\\n\".join(\n",
    "        [wikitext_detokenize(t) for t in dtest[\"text\"]]\n",
    "    ), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b866b6df-4a1f-4dff-9d1c-3ed0e123f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encodings.input_ids.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "caf25224-31e8-4fc2-83dc-706a8843badc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=0\n",
    "end=512\n",
    "n_ctx=512\n",
    "n_batch=512\n",
    "num_batches = 1\n",
    "batch_start = 0\n",
    "batch_sz = min(end-batch_start,n_batch)\n",
    "batch_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d142c7c-eeae-4168-9673-421669861e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_org = tokens[0][batch_start].item()\n",
    "token_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef894c2e-a2cd-4349-bbf6-df68c290da68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0e79da14-9a3c-4ad9-bd1a-f3b429806d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa56d9-0de7-4235-bf25-8eab2b13b891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e115311a-e469-4194-9883-6002b468b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = m(tokens[:,batch_start:(batch_start+batch_sz)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26cf050d-7da0-45c1-9458-b7de4de35618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 32000])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5734da6c-460f-4fca-83d6-4d7514855849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): ReLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "77bcc017-141d-4009-abd3-7d6c9021c7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaMLP(\n",
       "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "  (act_fn): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e6f77716-742c-4120-90ce-5229d3d4b948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 328887])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5275670-1464-4c79-b0bf-fd4a6f05a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_list = []\n",
    "stride = 2048\n",
    "    # TODO: last stride is dropped\n",
    "for i in range(0, encodings.input_ids.size(1)-stride, stride):\n",
    "    begin_loc = i\n",
    "    end_loc = min(i+stride, encodings.input_ids.size(1))\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "    input_ids_list.append(input_ids)\n",
    "input_ids = torch.cat(input_ids_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1dd0304e-9488-4975-a0c2-e430f4f6aca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a0c784b3b041629514058694cf8aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = Dataset.from_dict({\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': torch.ones_like(input_ids),\n",
    "        'idx': list(range(len(input_ids))),\n",
    "    })\n",
    "    \n",
    "train_set = train_set.map(lambda examples: {'text': examples['input_ids']}, batched=True)\n",
    "train_set.set_format(\n",
    "        type='torch', columns=[\n",
    "            'text', 'input_ids', 'attention_mask', 'idx',\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71d161a6-3b31-4928-b4fa-2433cb12fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 2048])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aafca125-e96f-4a8e-9222-5e341da97d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 328887])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f77cd19-1f02-4801-9199-a0cd5713dd0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_set,\n\u001b[0;32m----> 2\u001b[0m                                                     batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m      3\u001b[0m                                                     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                                                     num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[1;32m      5\u001b[0m                                                     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                                                     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                                                     collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                                    batch_size=args.batch_size,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=num_workers,\n",
    "                                                    drop_last=True,\n",
    "                                                    pin_memory=True,\n",
    "                                                    collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "828c1bac-a305-43cd-98cb-78ff1b1ec2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'idx': Value(dtype='int64', id=None),\n",
       " 'text': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "662352a5-c164-44c2-81cf-1106c4e483c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/shared/vsathia2/hf_models/relu-llama/', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4690af26-e9df-489c-bfe3-75c09dda6b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/shared/vsathia2/hf_models/relu-llama/\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_length\": 4096,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.40.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bf29983-b896-4d3b-8476-93005fe1c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk2 = AutoTokenizer.from_pretrained(\"/shared/vsathia2/hf_models/vanilla_llama/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "42a4c2c3-6a86-4585-8d1a-0f48f8f967de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/shared/vsathia2/hf_models/vanilla_llama/', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b4f88cd9-08a5-44b8-83ab-30ce4ab3158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "425b2f94-8301-4b0e-832a-b88eb00bf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encodings.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b55b40ff-af62-4039-86b5-af8200c32579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328887"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "40e24f78-55ec-4403-a374-bec2357256a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0]) // 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e90204e6-c9dc-401e-a029-f694c1240b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328704"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11f6ea87-124d-471d-bcdf-1436e528a19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for //: 'torch.Size' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m512\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'torch.Size' and 'int'"
     ]
    }
   ],
   "source": [
    "tokens.shape // 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc0d87-1175-4489-9e81-aa11ab28f3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
