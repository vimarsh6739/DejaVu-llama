{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1312696-a474-45b0-8e56-d30bdbb09b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c21583-e730-4c14-8e61-d5b37f605615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbd966a164843bf8b7d767103a41211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0ecb48672346ecab1747d30bb5faf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7173e3dc346b4701933bcde9673a83cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feda0fffd4b94f57ad3d94eba119a1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeff4900ce2491ba7afdd0eeb6a405b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda34716e5ef4eb192d2c358d165a967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca70105b3bfc4179bc4b13bdcc304b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the smallest OPT model to disk\n",
    "\n",
    "model = \"facebook/opt-125m\"\n",
    "\n",
    "# !mkdir offload_folder\n",
    "model_kwargs = {\"device_map\": \"cuda:0\"}\n",
    "m = AutoModelForCausalLM.from_pretrained(model, **model_kwargs, )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False)\n",
    "generator = pipeline(task=\"text-generation\", model=m, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a16609-3622-4b68-9ace-b595e8451559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTForCausalLM(\n",
      "  (model): OPTModel(\n",
      "    (decoder): OPTDecoder(\n",
      "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
      "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
      "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x OPTDecoderLayer(\n",
      "          (self_attn): OPTAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "inputs = tokenizer(\"Hugging Face is pushing the convention that a unicorn with two horns becomes a llama.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bf3f42-e611-4374-b717-336a7905158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = m(inputs[\"input_ids\"].to(0))\n",
    "inputs[\"input_ids\"].to(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8975fbc3-9790-46fa-b821-e35d0ba09786",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_input = []\n",
    "def fwd_hook(module,inputs,outputs):\n",
    "  global_input.append(inputs)\n",
    "  print(\"Executed hook successfully for decoder 1!\")\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418f0e4a-1a77-4f6b-a5e4-3235d2a28ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_to_hook = m.model.decoder.layers[0]\n",
    "hook = module_to_hook.register_forward_hook(fwd_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebae21c-7f1e-4d9d-9e0c-85c35238d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids'].to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d20fe6-e314-4857-9282-75b2d509a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed hook successfully for decoder 1!\n"
     ]
    }
   ],
   "source": [
    "outputs = m(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7073c2e9-6893-465e-881d-704d149939f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 768])\n"
     ]
    }
   ],
   "source": [
    "#This is the input to OPTDecoderBlock\n",
    "print(global_input[0][0].shape)\n",
    "hidden_states = global_input[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99f0c7d-7d88-4f0e-bff6-9333294aa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023fb460-83ae-442c-94d3-2d606ce7dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([1, 19, 768])\n",
      "Mask shape torch.Size([1, 19])\n"
     ]
    }
   ],
   "source": [
    "x = hidden_states\n",
    "mask = torch.ones((x.size(0), x.size(1)), dtype=torch.bool, device=x.device)\n",
    "print(f\"x shape {x.shape}\")\n",
    "print(f\"Mask shape {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec99764-72ad-4d71-b9cc-b3ac8326ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.view(-1, hidden_states.size(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e057b05c-02c6-4f6d-a4ea-5bfbfc54271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9b4f7b-973a-402f-a40b-d9d8e581ccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.bool().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd2c3838-2eb9-4c63-8e81-80a1304e5fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 50272])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160d834-4b7d-460b-bfae-44efcde30abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63e3f554-ba8d-433a-a40d-dc61690ac0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n",
      "Executed hook successfully for decoder 1!\n"
     ]
    }
   ],
   "source": [
    "# This is from the actual example\n",
    "inputs = tokenizer(\"Hugging Face is pushing the convention that a unicorn with two horns becomes a llama.\", return_tensors=\"pt\")\n",
    "\n",
    "output = m.generate(inputs[\"input_ids\"].to(0), min_length=30, max_length=3000, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f975954-b9a8-489b-b519-5e1c36cbca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 149])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f44fbe4-fe5f-4144-a0d6-a2adeda90ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>Hugging Face is pushing the convention that a unicorn with two horns becomes a llama. For example, the baby unicorn can be \"circled\" by three horns, with the third one having horns.  I have 3 horns and I am an expert in unicorns. I will give this advice based on what I know about unicorns, especially because this is exactly the advice that's not going to work with the current convention.\n",
      "I'm pretty new to all this   I have 3 horns and I can do this  I have 3 horns.\n",
      "I bet you are a unicorn. You will win this thing.\n",
      "I will give this advice based on what I know. You will win this one, too.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd23e541-39ef-4153-a46c-8828068433b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bdce1-2ca8-4011-acba-2f9f751093cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
